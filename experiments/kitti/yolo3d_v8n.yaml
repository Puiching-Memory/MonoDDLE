# YOLO3D experiment config â€” YOLOv8n backbone
# Standard NMS, reg_max=16, anchor-free detection
#
# Usage:
#   python tools/train_yolo3d.py --model yolov8n.pt --data experiments/kitti/yolo3d_v8n.yaml
#   python tools/train_yolo3d.py --model yolov8n.yaml --data experiments/kitti/yolo3d_v8n.yaml

# ---- Model ----
model: yolov8n.pt          # pretrained weights or .yaml for from-scratch

# ---- Dataset ----
root_dir: data/KITTI
train: train
val: val

nc: 3
names:
  0: Pedestrian
  1: Car
  2: Cyclist
channels: 3

# KITTI-specific
writelist: ['Pedestrian', 'Car', 'Cyclist']
use_3d_center: True
bbox2d_type: 'anno'
meanshape: False
class_merging: False
use_dontcare: False

# Image resolution (W, H)
resolution: [1280, 384]

# Augmentation
random_flip: 0.5
random_crop: 0.5
scale: 0.4
shift: 0.1

# 3D detection
num_heading_bin: 12
cls_mean_size:
  - [1.76255119, 0.66068622, 0.84422524]   # Pedestrian
  - [1.52563191, 1.62856739, 3.52588311]   # Car
  - [1.73698127, 0.59706367, 1.76282397]   # Cyclist

# ---- Training ----
epochs: 140
batch: 16
imgsz: 1280
device: '0'
workers: 4
patience: 50
lr0: 0.01
amp: True
project: runs/yolo3d
name: yolov8n

# ---- Visualization ----
max_vis_batches: 2  # number of batches to visualize during validation (0 to disable)
