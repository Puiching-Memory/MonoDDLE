% !TeX program = xelatex
\documentclass[UTF8,a4paper,11pt,fontset=none]{ctexart}

\usepackage[margin=1in]{geometry}
\usepackage{booktabs}
\usepackage{array}
\usepackage{longtable}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{listings}

\setCJKmainfont[AutoFakeBold=2.5,AutoFakeSlant=0.2]{AR PL UMing CN}
\setCJKsansfont{Droid Sans Fallback}
\setCJKmonofont{Droid Sans Fallback}

\hypersetup{
  colorlinks=true,
  linkcolor=blue,
  urlcolor=blue,
  citecolor=blue
}

\lstset{
  basicstyle=\ttfamily\small,
  breaklines=true,
  frame=single,
  columns=fullflexible,
  keepspaces=true,
  showstringspaces=false
}

\title{基于深度估计和不确定性引导的3D目标检测研究分析}
\author{}
\date{}

\begin{document}

\maketitle

\noindent\textbf{English README:} \href{README.md}{README.md}

\section{项目简介}

\textbf{MonoDDLE} (Monocular Dense Depth Distillation for Localization Errors) 是基于
\href{https://github.com/XinzhuMa/MonoDLE}{MonoDLE} 的改进版本。\textbf{论文暂未发表。}

3D目标检测的核心难点在于从单张RGB图像中恢复丢失的深度信息。现有的主流方法通常依赖稀疏的 LiDAR 点云真值进行监督训练，存在稀疏性和数据获取成本高的局限性。本项目旨在利用视觉基础模型（如 Depth Anything V3）的绝对度量深度作为“软标签”或“密集监督信号”，通过知识蒸馏的方式，指导轻量级单目检测器学习更鲁棒的深度特征，从而在不增加推理成本的前提下显著提升检测精度。

\section{可视化结果}

KITTI 数据集上的部分可视化结果：

\begin{figure}[htbp]
  \centering
  \begin{subfigure}[t]{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{docs/images/2d.png}
    \caption{2D 边界框}
  \end{subfigure}
  \hfill
  \begin{subfigure}[t]{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{docs/images/3d.png}
    \caption{3D 边界框}
  \end{subfigure}

  \vspace{0.5em}

  \begin{subfigure}[t]{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{docs/images/da3.png}
    \caption{DA3 深度伪标签}
  \end{subfigure}
  \hfill
  \begin{subfigure}[t]{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{docs/images/unc.png}
    \vspace{0.2em}
    \includegraphics[width=\textwidth]{docs/images/img.png}
    \caption{深度不确定性}
  \end{subfigure}

  \vspace{0.5em}

  \begin{subfigure}[t]{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{docs/images/hm.png}
    \vspace{0.2em}
    \includegraphics[width=\textwidth]{docs/images/hm_perclass.png}
    \caption{目标中心点热力图}
  \end{subfigure}
  \hfill
  \begin{subfigure}[t]{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{docs/images/lidar.png}
    \caption{LiDAR BEV 投影}
  \end{subfigure}
  \caption{KITTI 可视化结果示例}
\end{figure}

\noindent\textbf{注：}以上可视化结果对应的图像编号为 001230。

\section{实验结果}

我们在 KITTI 数据集上进行了广泛的实验，以下是部分核心实验结果（详细数据请参考仓库根目录下的 \texttt{summary.md}）。

\subsection{核心结果对比 (KITTI Validation Set)}

\begin{table}[htbp]
  \centering
  \caption{核心结果对比}
  \resizebox{\textwidth}{!}{%
  \begin{tabular}{lcccc}
    \toprule
    Method & 3D@0.7 (Easy/Mod/Hard) & BEV@0.7 (Easy/Mod/Hard) & 3D@0.5 (Easy/Mod/Hard) & BEV@0.5 (Easy/Mod/Hard) \\
    \midrule
    CenterNet & 0.60 / 0.66 / 0.77 & 3.46 / 3.31 / 3.21 & 20.00 / 17.50 / 15.57 & 34.36 / 27.91 / 24.65 \\
    MonoGRNet & 11.90 / 7.56 / 5.76 & 19.72 / 12.81 / 10.15 & 47.59 / 32.28 / 25.50 & 48.53 / 35.94 / 28.59 \\
    MonoDIS & 11.06 / 7.60 / 6.37 & 18.45 / 12.58 / 10.66 & - & - \\
    M3D-RPN & 14.53 / 11.07 / 8.65 & 20.85 / 15.62 / 11.88 & 48.53 / 35.94 / 28.59 & 53.35 / 39.60 / 31.76 \\
    MonoPair & 16.28 / 12.30 / 10.42 & 24.12 / 18.17 / 15.76 & 55.38 / 42.39 / 37.99 & 61.06 / 47.63 / 41.92 \\
    MonoDLE (Re-impl.) & 15.17 / 12.10 / 10.82 & 21.10 / 17.20 / 15.10 & 50.70 / 38.91 / 34.82 & 56.94 / 43.74 / 38.41 \\
    \textbf{MonoDDLE (Ours)} & \textbf{18.49 / 14.48 / 12.14} & \textbf{26.38 / 20.12 / 17.89} & \textbf{59.80 / 43.89 / 39.27} & \textbf{65.10 / 48.85 / 42.97} \\
    \bottomrule
  \end{tabular}}
\end{table}

\subsection{消融实验：DA3 深度与不确定性}

\begin{table}[htbp]
  \centering
  \caption{DA3 深度与不确定性消融}
  \resizebox{\textwidth}{!}{%
  \begin{tabular}{lcccc}
    \toprule
    Method & DA3 Depth & Uncertainty & 3D AP\textsubscript{R40} (E / M / H) & BEV AP\textsubscript{R40} (E / M / H) \\
    \midrule
    Baseline &  &  & 15.17 / 12.10 / 10.82 & 21.10 / 17.20 / 15.10 \\
    + DA3 & $\checkmark$ &  & 18.27 / 14.26 / 11.96 & 25.59 / 19.65 / 16.79 \\
    \textbf{+ Uncertainty} & \textbf{$\checkmark$} & \textbf{$\checkmark$} & \textbf{18.49 / 14.48 / 12.14} & \textbf{26.38 / 20.12 / 17.89} \\
    \bottomrule
  \end{tabular}}
\end{table}

\subsection{模型参数量与计算量对比}

\begin{table}[htbp]
  \centering
  \caption{模型复杂度对比}
  \resizebox{0.8\textwidth}{!}{%
  \begin{tabular}{lccc}
    \toprule
    Model & Backbone & FLOPs (G) & Params (M) \\
    \midrule
    MonoDLE & DLA-34 & 79.37 & 20.31 \\
    \textbf{MonoDDLE (Ours)} & \textbf{DLA-34} & \textbf{83.91} & \textbf{20.46} \\
    & HRNet-W32 & 212.25 & 48.91 \\
    & ResNet-50 & 439.70 & 91.41 \\
    & ConvNeXt-Tiny & 129.83 & 38.34 \\
    \bottomrule
  \end{tabular}}
\end{table}

\subsection{不同骨干网络的影响 (With DA3)}

\begin{table}[htbp]
  \centering
  \caption{不同骨干网络结果}
  \resizebox{\textwidth}{!}{%
  \begin{tabular}{lcc}
    \toprule
    Backbone & 3D AP\textsubscript{R40} (E / M / H) & BEV AP\textsubscript{R40} (E / M / H) \\
    \midrule
    DLA-34 & 17.52 / 13.59 / 12.06 & 25.46 / 19.69 / 17.01 \\
    HRNet-W32 & 17.87 / 13.72 / 11.73 & 24.79 / 19.23 / 16.58 \\
    ConvNeXtV2-Tiny & 17.17 / 13.25 / 11.69 & 24.97 / 19.42 / 16.74 \\
    ResNet-50 & 15.45 / 12.03 / 10.11 & 22.38 / 17.81 / 15.51 \\
    \bottomrule
  \end{tabular}}
\end{table}

\section{使用说明}

\subsection{环境安装}

使用 \texttt{uv} 管理 Python 环境与依赖（项目默认使用仓库内 \texttt{.venv}）：

\begin{lstlisting}[language=bash]
cd #ROOT
# Install dependencies into local virtual environment
uv venv .venv
source .venv/bin/activate
uv pip install -r requirements.txt
\end{lstlisting}

\subsection{数据准备}

请先下载 \href{http://www.cvlibs.net/datasets/kitti/eval_object.php?obj_benchmark=3d}{KITTI 数据集}，并按以下结构组织：

\begin{lstlisting}
MonoDDLE/
  data/
    KITTI/
      ImageSets/            # split files
      training/
        calib/
        image_2/
        label_2/
      testing/
        calib/
        image_2/
      DA3_depth_results/    # required for DA3 distillation
        000000.npz
        000000_vis.jpg
        000001.npz
        000001_vis.jpg
        ...
\end{lstlisting}

生成 DA3 深度数据的脚本如下（需确保已安装 \texttt{depth\_anything\_3}）：

\begin{lstlisting}[language=bash]
python tools/generate_da3_depth.py --data_path data/KITTI --split training
\end{lstlisting}

该脚本会为每张图像生成两个文件：
\begin{itemize}
  \item \textbf{.npz}：包含 \texttt{depth} (H, W)、\texttt{intrinsics} (3, 3)、\texttt{extrinsics} (3, 4) 三个键，分别为 DA3 预测的度量深度图、相机内参和外参矩阵。
  \item \textbf{\_vis.jpg}：原图与彩色深度图的上下拼接可视化（用于快速检查深度质量）。
\end{itemize}

\noindent\textbf{注：}训练时仅使用 \texttt{.npz} 中的 \texttt{depth} 键，\texttt{intrinsics} 和 \texttt{extrinsics} 为辅助信息。

\subsection{训练与评估}

\texttt{tools/train\_val.py} 会将 \texttt{dataset.root\_dir} 作为相对项目根目录进行解析，因此可直接在仓库根目录执行命令。

\subsubsection*{单进程 DP（默认，DataParallel）}

\begin{lstlisting}[language=bash]
cd #ROOT
# Run MonoDDLE with uncertainty distillation
python tools/train_val.py --config experiments/configs/monodle/kitti_da3_uncertainty.yaml
\end{lstlisting}

\subsubsection*{多进程 DDP（DistributedDataParallel）}

\begin{lstlisting}[language=bash]
cd #ROOT
# Use all visible GPUs automatically
bash experiments/scripts/train_ddp.sh experiments/configs/monodle/kitti_da3_uncertainty.yaml

python tools/train_val.py --config experiments/kitti/monodle_kitti.yaml

python tools/train_val.py --config experiments/configs/monodle/kitti_da3_uncertainty.yaml -e
\end{lstlisting}

\subsection{DA3 深度蒸馏与不确定性}

\subsubsection*{DA3 深度蒸馏}

本项目使用 \href{https://github.com/DepthAnything/Depth-Anything-V3}{Depth Anything V3} 作为教师模型，预先生成全图稠密度量深度图作为伪标签，并通过蒸馏损失对检测器的深度预测头进行额外监督，无需改变检测器骨干网络结构。

在运行深度蒸馏训练前，需先生成 DA3 深度伪标签（参见第 2 节数据准备）：

\begin{lstlisting}[language=bash]
python tools/generate_da3_depth.py --data_path data/KITTI --split training
\end{lstlisting}

每个 \texttt{.npz} 文件包含 \texttt{depth}、\texttt{intrinsics}、\texttt{extrinsics} 三个键，同时生成 \texttt{\_vis.jpg} 可视化图片。训练时仅读取 \texttt{depth} 键。

蒸馏总损失为：

\[
L_{total} = L_{cls} + L_{bbox} + L_{dim} + \lambda \cdot L_{distill}
\]

其中 $L_{distill}$ 为预测深度与 DA3 伪标签之间的 L1 或 SiLog 损失，$\lambda$ 为蒸馏权重。开启深度蒸馏的最小 YAML 配置如下：

\begin{lstlisting}
dataset:
  use_da3_depth: True
\end{lstlisting}

\subsubsection*{不确定性引导的自适应蒸馏}

在 DA3 深度蒸馏的基础上，进一步引入\textbf{逐像素不确定性预测}，使模型对 DA3 伪标签的置信度进行自适应建模。不确定性高的区域（如反光表面、遮挡边界）将自动降低蒸馏损失权重，从而减轻噪声伪标签的负面影响：

\[
L_{distill}^{unc} = \frac{1}{N} \sum_{i} \frac{|d_i - \hat{d}_i|}{\sigma_i} + \log \sigma_i
\]

其中 $\sigma_i$ 为模型预测的深度不确定性，$d_i$ 为 DA3 伪标签，$\hat{d}_i$ 为模型预测深度。开启不确定性引导只需在 YAML 中设置：

\begin{lstlisting}
dataset:
  use_da3_depth: True # must enable DA3 depth distillation

distill:
  lambda: 0.5
  loss_type: 'l1'           # 'l1' or 'silog'
  foreground_weight: 5.0
  use_uncertainty: True     # enable uncertainty-guided distillation
\end{lstlisting}

\section{致谢}

感谢 \href{https://github.com/XinzhuMa/MonoDLE}{MonoDLE} 和 \href{https://github.com/xingyizhou/CenterNet}{CenterNet} 的优秀实现。

\section{许可证}

本项目采用 MIT License 开源。

\end{document}
